{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission Notebook For Jane Street Real-Time Market Data Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-24T15:41:06.623052Z",
     "iopub.status.busy": "2025-01-24T15:41:06.622629Z",
     "iopub.status.idle": "2025-01-24T15:41:06.628215Z",
     "shell.execute_reply": "2025-01-24T15:41:06.627326Z",
     "shell.execute_reply.started": "2025-01-24T15:41:06.623022Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib \n",
    "\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pytorch_lightning as lightning\n",
    "from pytorch_lightning import (LightningDataModule, LightningModule, Trainer)\n",
    "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint, Timer\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-24T15:41:06.629764Z",
     "iopub.status.busy": "2025-01-24T15:41:06.629456Z",
     "iopub.status.idle": "2025-01-24T15:41:06.642048Z",
     "shell.execute_reply": "2025-01-24T15:41:06.641414Z",
     "shell.execute_reply.started": "2025-01-24T15:41:06.629734Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "features = [\"symbol_id\", \"time_id\"] + [f\"feature_{idx:02d}\" for idx in range(79)] + [f\"responder_{idx}_lag_1\" for idx in range(9)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-24T15:41:06.644122Z",
     "iopub.status.busy": "2025-01-24T15:41:06.643857Z",
     "iopub.status.idle": "2025-01-24T15:41:06.656784Z",
     "shell.execute_reply": "2025-01-24T15:41:06.655894Z",
     "shell.execute_reply.started": "2025-01-24T15:41:06.644101Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class NN(LightningModule):\n",
    "    def __init__(self, input_dim, hidden_dims, dropouts, lr, weight_decay):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        layers = []\n",
    "        in_dim = input_dim\n",
    "        for i, hidden_dim in enumerate(hidden_dims):\n",
    "            layers.append(nn.BatchNorm1d(in_dim))\n",
    "            if i > 0:\n",
    "                layers.append(nn.ReLU())\n",
    "            if i < len(dropouts):\n",
    "                layers.append(nn.Dropout(dropouts[i]))\n",
    "            layers.append(nn.Linear(in_dim, hidden_dim))\n",
    "            in_dim = hidden_dim\n",
    "        layers.append(nn.Linear(in_dim, 1)) \n",
    "        layers.append(nn.Tanh())\n",
    "        self.model = nn.Sequential(*layers)\n",
    "        self.lr = lr\n",
    "        self.weight_decay = weight_decay\n",
    "        self.validation_step_outputs = []\n",
    "\n",
    "    def forward(self, x):\n",
    "        return 5 * self.model(x).squeeze(-1)  \n",
    "\n",
    "    def training_step(self, batch):\n",
    "        x, y, w = batch\n",
    "        y_pred = self(x)\n",
    "        loss = F.mse_loss(y_pred, y, reduction='none') * w  #\n",
    "        loss = loss.mean()\n",
    "        self.log('train_loss', loss, on_step=False, on_epoch=True, batch_size=x.size(0))\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch):\n",
    "        x, y, w = batch\n",
    "        y_hat = self(x)\n",
    "        loss = F.mse_loss(y_hat, y, reduction='none') * w\n",
    "        loss = loss.mean()\n",
    "        self.log('val_loss', loss, on_step=False, on_epoch=True, batch_size=x.size(0))\n",
    "        self.validation_step_outputs.append((y_hat, y, w))\n",
    "        return loss\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        \"\"\"Calculate validation WRMSE at the end of the epoch.\"\"\"\n",
    "        y = torch.cat([x[1] for x in self.validation_step_outputs]).cpu().numpy()\n",
    "        if self.trainer.sanity_checking:\n",
    "            prob = torch.cat([x[0] for x in self.validation_step_outputs]).cpu().numpy()\n",
    "        else:\n",
    "            prob = torch.cat([x[0] for x in self.validation_step_outputs]).cpu().numpy()\n",
    "            weights = torch.cat([x[2] for x in self.validation_step_outputs]).cpu().numpy()\n",
    "            # r2_val\n",
    "            val_r_square = r2_val(y, prob, weights)\n",
    "            self.log(\"val_r_square\", val_r_square, prog_bar=True, on_step=False, on_epoch=True)\n",
    "        self.validation_step_outputs.clear()\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.lr, weight_decay=self.weight_decay)\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5,\n",
    "                                                               verbose=True)\n",
    "        return {\n",
    "            'optimizer': optimizer,\n",
    "            'lr_scheduler': {\n",
    "                'scheduler': scheduler,\n",
    "                'monitor': 'val_loss',\n",
    "            }\n",
    "        }\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "        if self.trainer.sanity_checking:\n",
    "            return\n",
    "        epoch = self.trainer.current_epoch\n",
    "        metrics = {k: v.item() if isinstance(v, torch.Tensor) else v for k, v in self.trainer.logged_metrics.items()}\n",
    "        formatted_metrics = {k: f\"{v:.5f}\" for k, v in metrics.items()}\n",
    "        print(f\"Epoch {epoch}: {formatted_metrics}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-24T15:41:06.658168Z",
     "iopub.status.busy": "2025-01-24T15:41:06.657872Z",
     "iopub.status.idle": "2025-01-24T15:41:07.371167Z",
     "shell.execute_reply": "2025-01-24T15:41:07.370501Z",
     "shell.execute_reply.started": "2025-01-24T15:41:06.658141Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model_nn=NN.load_from_checkpoint(\"/kaggle/input/jane-st.-neural-network/pytorch/default/1/nn.model.ckpt\")\n",
    "model_xgb=None\n",
    "with open('/kaggle/input/jane-st.-xgb/other/default/1/xgb_model.pkl', 'rb') as file:\n",
    "    model_xgb=pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-24T15:41:07.372091Z",
     "iopub.status.busy": "2025-01-24T15:41:07.371898Z",
     "iopub.status.idle": "2025-01-24T15:41:07.379549Z",
     "shell.execute_reply": "2025-01-24T15:41:07.378669Z",
     "shell.execute_reply.started": "2025-01-24T15:41:07.372074Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "lags_ : pl.DataFrame | None = None\n",
    "    \n",
    "def predict(test: pl.DataFrame, lags: pl.DataFrame | None) -> pl.DataFrame | pd.DataFrame:\n",
    "    global lags_\n",
    "    if lags is not None:\n",
    "        lags_ = lags\n",
    "\n",
    "    predictions = test.select(\n",
    "        'row_id',\n",
    "        pl.lit(0.0).alias('responder_6'),\n",
    "    )\n",
    "    symbol_ids = test.select('symbol_id').to_numpy()[:, 0]\n",
    "\n",
    "    if not lags is None:\n",
    "        lags = lags.group_by([\"date_id\", \"symbol_id\"], maintain_order=True).last() # pick up last record of previous date\n",
    "        test = test.join(lags, on=[\"date_id\", \"symbol_id\"],  how=\"left\")\n",
    "    else:\n",
    "        test = test.with_columns(\n",
    "            ( pl.lit(0.0).alias(f'responder_{idx}_lag_1') for idx in range(9) )\n",
    "        )\n",
    "    \n",
    "    preds = np.zeros((test.shape[0],))\n",
    "    preds+= model_xgb.predict(test[features].to_pandas()) / 2\n",
    "    test_input = test[features].to_pandas()\n",
    "    test_input = test_input.fillna(method = 'ffill').fillna(0)\n",
    "    test_input = torch.FloatTensor(test_input.values).to(device)\n",
    "    with torch.no_grad():\n",
    "        model_nn.eval()\n",
    "        preds += model_nn(test_input).cpu().numpy() / 2\n",
    "    print(f\"predict> preds.shape =\", preds.shape)\n",
    "    \n",
    "    predictions = \\\n",
    "    test.select('row_id').\\\n",
    "    with_columns(\n",
    "        pl.Series(\n",
    "            name   = 'responder_6', \n",
    "            values = np.clip(preds, a_min = -5, a_max = 5),\n",
    "            dtype  = pl.Float64,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # The predict function must return a DataFrame\n",
    "    assert isinstance(predictions, pl.DataFrame | pd.DataFrame)\n",
    "    # with columns 'row_id', 'responer_6'\n",
    "    assert list(predictions.columns) == ['row_id', 'responder_6']\n",
    "    # and as many rows as the test data.\n",
    "    assert len(predictions) == len(test)\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "inference_server = kaggle_evaluation.jane_street_inference_server.JSInferenceServer(predict)\n",
    "\n",
    "if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
    "    inference_server.serve()\n",
    "else:\n",
    "    inference_server.run_local_gateway(\n",
    "        (\n",
    "            '/kaggle/input/jane-street-realtime-marketdata-forecasting/test.parquet',\n",
    "            '/kaggle/input/jane-street-realtime-marketdata-forecasting/lags.parquet',\n",
    "        )\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 9871156,
     "sourceId": 84493,
     "sourceType": "competition"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 226208,
     "modelInstanceId": 204472,
     "sourceId": 239468,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 227772,
     "modelInstanceId": 206026,
     "sourceId": 241164,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30840,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
