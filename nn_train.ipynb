{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Training Notebook For Jane Street Real-Time Market Data Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-23T18:04:06.303992Z",
     "iopub.status.busy": "2025-01-23T18:04:06.303771Z",
     "iopub.status.idle": "2025-01-23T18:04:18.111283Z",
     "shell.execute_reply": "2025-01-23T18:04:18.110228Z",
     "shell.execute_reply.started": "2025-01-23T18:04:06.303970Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib \n",
    "\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pytorch_lightning as lightning\n",
    "from pytorch_lightning import (LightningDataModule, LightningModule, Trainer)\n",
    "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint, Timer\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-23T16:44:51.586459Z",
     "iopub.status.busy": "2025-01-23T16:44:51.585924Z",
     "iopub.status.idle": "2025-01-23T16:44:51.591704Z",
     "shell.execute_reply": "2025-01-23T16:44:51.590727Z",
     "shell.execute_reply.started": "2025-01-23T16:44:51.586426Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "target=\"responder_6\"\n",
    "start_date_id = 1448 #use last 250 days\n",
    "lags_cols = [\"date_id\", \"symbol_id\"] + [f\"responder_{idx}\" for idx in range(9)]\n",
    "validation_ratio=0.05\n",
    "features = [\"symbol_id\", \"time_id\"] + [f\"feature_{idx:02d}\" for idx in range(79)] + [f\"responder_{idx}_lag_1\" for idx in range(9)]\n",
    "SEED=42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-23T16:44:51.593449Z",
     "iopub.status.busy": "2025-01-23T16:44:51.593221Z",
     "iopub.status.idle": "2025-01-23T16:44:51.636324Z",
     "shell.execute_reply": "2025-01-23T16:44:51.635534Z",
     "shell.execute_reply.started": "2025-01-23T16:44:51.593429Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train = pl.scan_parquet(\n",
    "    f\"/kaggle/input/jane-street-real-time-market-data-forecasting/train.parquet\"\n",
    ").select(\n",
    "    pl.int_range(pl.len(), dtype=pl.UInt32).alias(\"id\"),\n",
    "    pl.all(),\n",
    ").with_columns(\n",
    "    (pl.col(target)*2).cast(pl.Int32).alias(\"label\"),\n",
    ").filter(\n",
    "    pl.col(\"date_id\").gt(start_date_id)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-23T16:44:51.637621Z",
     "iopub.status.busy": "2025-01-23T16:44:51.637417Z",
     "iopub.status.idle": "2025-01-23T16:44:51.651715Z",
     "shell.execute_reply": "2025-01-23T16:44:51.650771Z",
     "shell.execute_reply.started": "2025-01-23T16:44:51.637602Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "lags = train.select(pl.col(lags_cols))\n",
    "lags_cols_rename = { f\"responder_{idx}\" : f\"responder_{idx}_lag_1\" for idx in range(9)}\n",
    "lags = lags.rename(lags_cols_rename)\n",
    "lags = lags.with_columns(\n",
    "    date_id = pl.col('date_id') + 1,  # 1 day lag\n",
    "    )\n",
    "lags = lags.group_by([\"date_id\", \"symbol_id\"], maintain_order=True).last()  # pick up last record of previous date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-23T16:44:51.652973Z",
     "iopub.status.busy": "2025-01-23T16:44:51.652691Z",
     "iopub.status.idle": "2025-01-23T16:44:51.669531Z",
     "shell.execute_reply": "2025-01-23T16:44:51.668748Z",
     "shell.execute_reply.started": "2025-01-23T16:44:51.652945Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train = train.join(lags, on=[\"date_id\", \"symbol_id\"],  how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-23T16:44:51.670734Z",
     "iopub.status.busy": "2025-01-23T16:44:51.670417Z",
     "iopub.status.idle": "2025-01-23T16:46:24.237263Z",
     "shell.execute_reply": "2025-01-23T16:46:24.236267Z",
     "shell.execute_reply.started": "2025-01-23T16:44:51.670702Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len_set=9217296\n",
      "len_train=8756432\n",
      "Last offline train date = 1686\n",
      "\n"
     ]
    }
   ],
   "source": [
    "len_set   = train.select(pl.col(\"date_id\")).collect().shape[0]\n",
    "len_validation = int(len_set * validation_ratio)\n",
    "len_train = len_set - len_validation\n",
    "last_train_date  = train.select(pl.col(\"date_id\")).collect().row(len_train)[0]\n",
    "\n",
    "print(f\"{len_set=}\")\n",
    "print(f\"{len_train=}\")\n",
    "print(f\"Last offline train date = {last_train_date}\\n\")\n",
    "\n",
    "training_data = train.filter(pl.col(\"date_id\").le(last_train_date)).collect()\n",
    "validation_data = train.filter(pl.col(\"date_id\").gt(last_train_date)).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-23T16:46:24.238547Z",
     "iopub.status.busy": "2025-01-23T16:46:24.238230Z",
     "iopub.status.idle": "2025-01-23T16:46:30.301199Z",
     "shell.execute_reply": "2025-01-23T16:46:30.299962Z",
     "shell.execute_reply.started": "2025-01-23T16:46:24.238519Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_df=training_data.to_pandas()\n",
    "val_df=validation_data.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-23T16:46:30.304942Z",
     "iopub.status.busy": "2025-01-23T16:46:30.304673Z",
     "iopub.status.idle": "2025-01-23T16:46:30.338065Z",
     "shell.execute_reply": "2025-01-23T16:46:30.337454Z",
     "shell.execute_reply.started": "2025-01-23T16:46:30.304918Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-23T16:46:30.339629Z",
     "iopub.status.busy": "2025-01-23T16:46:30.339288Z",
     "iopub.status.idle": "2025-01-23T16:46:30.343694Z",
     "shell.execute_reply": "2025-01-23T16:46:30.342829Z",
     "shell.execute_reply.started": "2025-01-23T16:46:30.339595Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def r2_val(y_true, y_pred, sample_weight):\n",
    "    r2 = 1 - np.average((y_pred - y_true) ** 2, weights=sample_weight) / (np.average((y_true) ** 2, weights=sample_weight) + 1e-38)\n",
    "    return r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-23T16:46:30.344760Z",
     "iopub.status.busy": "2025-01-23T16:46:30.344514Z",
     "iopub.status.idle": "2025-01-23T16:46:30.354750Z",
     "shell.execute_reply": "2025-01-23T16:46:30.354037Z",
     "shell.execute_reply.started": "2025-01-23T16:46:30.344732Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class JaneStreetDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.features = torch.FloatTensor(df[features].values)\n",
    "        self.labels = torch.FloatTensor(df[target].values)\n",
    "        self.weights = torch.FloatTensor(df[\"weight\"].values)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x = self.features[idx]\n",
    "        y = self.labels[idx]\n",
    "        w = self.weights[idx]\n",
    "        return x, y, w\n",
    "\n",
    "class DataModule(LightningDataModule):\n",
    "    def __init__(self, train_df, batch_size, val_df):\n",
    "        super().__init__()\n",
    "        self.df = train_df.copy()\n",
    "        self.batch_size = batch_size\n",
    "        self.dates = self.df['date_id'].unique()\n",
    "        self.train_dataset = None\n",
    "        self.val_df = val_df.copy()\n",
    "        self.val_dataset = None\n",
    "\n",
    "    def setup_folds(self, fold=0, N_fold=5):\n",
    "        selected_dates = [date for ii, date in enumerate(self.dates) if ii % N_fold != fold]\n",
    "        df_train = self.df.loc[self.df['date_id'].isin(selected_dates)]\n",
    "        self.train_dataset = JaneStreetDataset(df_train)\n",
    "        if self.val_df is not None:\n",
    "            self.val_dataset = JaneStreetDataset(self.val_df)\n",
    "\n",
    "    def setup_single(self):\n",
    "        self.train_dataset = JaneStreetDataset(self.df)\n",
    "        if self.val_df is not None:\n",
    "            self.val_dataset = JaneStreetDataset(self.val_df)\n",
    "            \n",
    "    def train_dataloader(self, n_workers=0):\n",
    "        return DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=True, num_workers=n_workers)\n",
    "\n",
    "    def val_dataloader(self, n_workers=0):\n",
    "        return DataLoader(self.val_dataset, batch_size=self.batch_size, shuffle=False, num_workers=n_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-23T16:46:30.355788Z",
     "iopub.status.busy": "2025-01-23T16:46:30.355520Z",
     "iopub.status.idle": "2025-01-23T16:46:30.370986Z",
     "shell.execute_reply": "2025-01-23T16:46:30.370319Z",
     "shell.execute_reply.started": "2025-01-23T16:46:30.355759Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class NN(LightningModule):\n",
    "    def __init__(self, input_dim, hidden_dims, dropouts, lr, weight_decay):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        layers = []\n",
    "        in_dim = input_dim\n",
    "        for i, hidden_dim in enumerate(hidden_dims):\n",
    "            layers.append(nn.BatchNorm1d(in_dim))\n",
    "            if i > 0:\n",
    "                layers.append(nn.ReLU())\n",
    "            if i < len(dropouts):\n",
    "                layers.append(nn.Dropout(dropouts[i]))\n",
    "            layers.append(nn.Linear(in_dim, hidden_dim))\n",
    "            in_dim = hidden_dim\n",
    "        layers.append(nn.Linear(in_dim, 1)) \n",
    "        layers.append(nn.Tanh())\n",
    "        self.model = nn.Sequential(*layers)\n",
    "        self.lr = lr\n",
    "        self.weight_decay = weight_decay\n",
    "        self.validation_step_outputs = []\n",
    "\n",
    "    def forward(self, x):\n",
    "        return 5 * self.model(x).squeeze(-1)  \n",
    "\n",
    "    def training_step(self, batch):\n",
    "        x, y, w = batch\n",
    "        y_pred = self(x)\n",
    "        loss = F.mse_loss(y_pred, y, reduction='none') * w  \n",
    "        loss = loss.mean()\n",
    "        self.log('train_loss', loss, on_step=False, on_epoch=True, batch_size=x.size(0))\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch):\n",
    "        x, y, w = batch\n",
    "        y_hat = self(x)\n",
    "        loss = F.mse_loss(y_hat, y, reduction='none') * w\n",
    "        loss = loss.mean()\n",
    "        self.log('val_loss', loss, on_step=False, on_epoch=True, batch_size=x.size(0))\n",
    "        self.validation_step_outputs.append((y_hat, y, w))\n",
    "        return loss\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        \"\"\"Calculate validation WRMSE at the end of the epoch.\"\"\"\n",
    "        y = torch.cat([x[1] for x in self.validation_step_outputs]).cpu().numpy()\n",
    "        if self.trainer.sanity_checking:\n",
    "            prob = torch.cat([x[0] for x in self.validation_step_outputs]).cpu().numpy()\n",
    "        else:\n",
    "            prob = torch.cat([x[0] for x in self.validation_step_outputs]).cpu().numpy()\n",
    "            weights = torch.cat([x[2] for x in self.validation_step_outputs]).cpu().numpy()\n",
    "            val_r_square = r2_val(y, prob, weights)\n",
    "            self.log(\"val_r_square\", val_r_square, prog_bar=True, on_step=False, on_epoch=True)\n",
    "        self.validation_step_outputs.clear()\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.lr, weight_decay=self.weight_decay)\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5,\n",
    "                                                               verbose=True)\n",
    "        return {\n",
    "            'optimizer': optimizer,\n",
    "            'lr_scheduler': {\n",
    "                'scheduler': scheduler,\n",
    "                'monitor': 'val_loss',\n",
    "            }\n",
    "        }\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "        if self.trainer.sanity_checking:\n",
    "            return\n",
    "        epoch = self.trainer.current_epoch\n",
    "        metrics = {k: v.item() if isinstance(v, torch.Tensor) else v for k, v in self.trainer.logged_metrics.items()}\n",
    "        formatted_metrics = {k: f\"{v:.5f}\" for k, v in metrics.items()}\n",
    "        print(f\"Epoch {epoch}: {formatted_metrics}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-23T16:46:30.372142Z",
     "iopub.status.busy": "2025-01-23T16:46:30.371845Z",
     "iopub.status.idle": "2025-01-23T16:47:21.179673Z",
     "shell.execute_reply": "2025-01-23T16:47:21.178923Z",
     "shell.execute_reply.started": "2025-01-23T16:46:30.372105Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-12-7cbf88b8560b>:1: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  train_df[features] = train_df[features].fillna(method = 'ffill').fillna(0)\n",
      "<ipython-input-12-7cbf88b8560b>:2: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  val_df[features] = val_df[features].fillna(method = 'ffill').fillna(0)\n"
     ]
    }
   ],
   "source": [
    "train_df[features] = train_df[features].fillna(method = 'ffill').fillna(0)\n",
    "val_df[features] = val_df[features].fillna(method = 'ffill').fillna(0)\n",
    "data_module = DataModule(train_df, batch_size=8192, val_df=val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-23T16:47:21.180759Z",
     "iopub.status.busy": "2025-01-23T16:47:21.180478Z",
     "iopub.status.idle": "2025-01-23T16:47:21.193700Z",
     "shell.execute_reply": "2025-01-23T16:47:21.192996Z",
     "shell.execute_reply.started": "2025-01-23T16:47:21.180733Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "lightning.seed_everything(42)\n",
    "RUN_CROSSVAL=False\n",
    "if RUN_CROSSVAL:\n",
    "    for fold in range(5):\n",
    "        data_module.setup_folds(fold, 5)\n",
    "        # Obtain input dimension\n",
    "        input_dim = data_module.train_dataset.features.shape[1]\n",
    "        # Initialize Model\n",
    "        model = NN(\n",
    "            input_dim=input_dim,\n",
    "            hidden_dims=[512, 512, 256],\n",
    "            dropouts=[0.1, 0.1],\n",
    "            lr=1e-3,\n",
    "            weight_decay=5e-4\n",
    "        )\n",
    "        # Initialize Callbacks\n",
    "        early_stopping = EarlyStopping('val_loss', patience=25, mode='min', verbose=False)\n",
    "        checkpoint_callback = ModelCheckpoint(monitor='val_loss', mode='min', save_top_k=1, verbose=False, filename=f\"/kaggle/working/models/nn_{fold}.model\") \n",
    "        timer = Timer()\n",
    "        # Initialize Trainer\n",
    "        trainer = Trainer(\n",
    "            max_epochs=2000,\n",
    "            accelerator=device,\n",
    "            #devices=[0] if torch.cuda.is_available() else None,\n",
    "            logger=None,\n",
    "            callbacks=[early_stopping, checkpoint_callback, timer],\n",
    "            enable_progress_bar=True\n",
    "        )\n",
    "        # Start Training\n",
    "        trainer.fit(model, data_module.train_dataloader(4), data_module.val_dataloader(4))\n",
    "        print(f'Fold-{fold} Training completed in {timer.time_elapsed(\"train\"):.2f}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-23T16:47:21.194653Z",
     "iopub.status.busy": "2025-01-23T16:47:21.194422Z",
     "iopub.status.idle": "2025-01-23T17:51:37.675487Z",
     "shell.execute_reply": "2025-01-23T17:51:37.674416Z",
     "shell.execute_reply.started": "2025-01-23T16:47:21.194632Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: {'val_loss': '1.05061', 'val_r_square': '-0.00204', 'train_loss': '1.57411'}\n",
      "Epoch 1: {'val_loss': '1.05146', 'val_r_square': '-0.00285', 'train_loss': '1.51174'}\n",
      "Epoch 2: {'val_loss': '1.04941', 'val_r_square': '-0.00090', 'train_loss': '1.50733'}\n",
      "Epoch 3: {'val_loss': '1.04678', 'val_r_square': '0.00161', 'train_loss': '1.50604'}\n",
      "Epoch 4: {'val_loss': '1.04722', 'val_r_square': '0.00120', 'train_loss': '1.50341'}\n",
      "Epoch 5: {'val_loss': '1.04750', 'val_r_square': '0.00093', 'train_loss': '1.49982'}\n",
      "Epoch 6: {'val_loss': '1.04600', 'val_r_square': '0.00236', 'train_loss': '1.49641'}\n",
      "Epoch 7: {'val_loss': '1.04478', 'val_r_square': '0.00352', 'train_loss': '1.49425'}\n",
      "Epoch 8: {'val_loss': '1.04578', 'val_r_square': '0.00257', 'train_loss': '1.49223'}\n",
      "Epoch 9: {'val_loss': '1.04598', 'val_r_square': '0.00237', 'train_loss': '1.49020'}\n",
      "Epoch 10: {'val_loss': '1.04855', 'val_r_square': '-0.00007', 'train_loss': '1.48968'}\n",
      "Epoch 11: {'val_loss': '1.04565', 'val_r_square': '0.00269', 'train_loss': '1.48838'}\n",
      "Epoch 12: {'val_loss': '1.04698', 'val_r_square': '0.00142', 'train_loss': '1.48698'}\n",
      "Epoch 13: {'val_loss': '1.04648', 'val_r_square': '0.00190', 'train_loss': '1.48645'}\n",
      "Epoch 14: {'val_loss': '1.04671', 'val_r_square': '0.00168', 'train_loss': '1.48166'}\n",
      "Epoch 15: {'val_loss': '1.04680', 'val_r_square': '0.00159', 'train_loss': '1.48096'}\n",
      "Epoch 16: {'val_loss': '1.04451', 'val_r_square': '0.00378', 'train_loss': '1.48005'}\n",
      "Epoch 17: {'val_loss': '1.04634', 'val_r_square': '0.00203', 'train_loss': '1.48000'}\n",
      "Epoch 18: {'val_loss': '1.04286', 'val_r_square': '0.00535', 'train_loss': '1.47912'}\n",
      "Epoch 19: {'val_loss': '1.04584', 'val_r_square': '0.00250', 'train_loss': '1.47881'}\n",
      "Epoch 20: {'val_loss': '1.04727', 'val_r_square': '0.00114', 'train_loss': '1.47818'}\n",
      "Epoch 21: {'val_loss': '1.04621', 'val_r_square': '0.00215', 'train_loss': '1.47800'}\n",
      "Epoch 22: {'val_loss': '1.04624', 'val_r_square': '0.00213', 'train_loss': '1.47796'}\n",
      "Epoch 23: {'val_loss': '1.04476', 'val_r_square': '0.00354', 'train_loss': '1.47746'}\n",
      "Epoch 24: {'val_loss': '1.04685', 'val_r_square': '0.00154', 'train_loss': '1.47681'}\n",
      "Epoch 25: {'val_loss': '1.04700', 'val_r_square': '0.00140', 'train_loss': '1.47422'}\n",
      "Epoch 26: {'val_loss': '1.04578', 'val_r_square': '0.00256', 'train_loss': '1.47400'}\n",
      "Epoch 27: {'val_loss': '1.04653', 'val_r_square': '0.00185', 'train_loss': '1.47345'}\n",
      "Epoch 28: {'val_loss': '1.04610', 'val_r_square': '0.00226', 'train_loss': '1.47289'}\n",
      "Epoch 29: {'val_loss': '1.04680', 'val_r_square': '0.00159', 'train_loss': '1.47300'}\n",
      "Epoch 30: {'val_loss': '1.04818', 'val_r_square': '0.00028', 'train_loss': '1.47327'}\n",
      "Epoch 31: {'val_loss': '1.04689', 'val_r_square': '0.00151', 'train_loss': '1.47099'}\n",
      "Epoch 32: {'val_loss': '1.04656', 'val_r_square': '0.00182', 'train_loss': '1.47053'}\n",
      "Epoch 33: {'val_loss': '1.04768', 'val_r_square': '0.00076', 'train_loss': '1.47051'}\n",
      "Epoch 34: {'val_loss': '1.04583', 'val_r_square': '0.00252', 'train_loss': '1.47047'}\n",
      "Epoch 35: {'val_loss': '1.04635', 'val_r_square': '0.00203', 'train_loss': '1.47060'}\n",
      "Epoch 36: {'val_loss': '1.04698', 'val_r_square': '0.00142', 'train_loss': '1.47002'}\n",
      "Epoch 37: {'val_loss': '1.04689', 'val_r_square': '0.00151', 'train_loss': '1.46889'}\n",
      "Epoch 38: {'val_loss': '1.04766', 'val_r_square': '0.00077', 'train_loss': '1.46858'}\n",
      "Epoch 39: {'val_loss': '1.04598', 'val_r_square': '0.00237', 'train_loss': '1.46854'}\n",
      "Epoch 40: {'val_loss': '1.04589', 'val_r_square': '0.00246', 'train_loss': '1.46883'}\n",
      "Epoch 41: {'val_loss': '1.04618', 'val_r_square': '0.00218', 'train_loss': '1.46843'}\n",
      "Epoch 42: {'val_loss': '1.04661', 'val_r_square': '0.00177', 'train_loss': '1.46899'}\n",
      "Epoch 43: {'val_loss': '1.04694', 'val_r_square': '0.00146', 'train_loss': '1.46781'}\n",
      "Training completed in 3835.58s\n"
     ]
    }
   ],
   "source": [
    "RUN_SINGLE=True\n",
    "if RUN_SINGLE:\n",
    "    data_module.setup_single()\n",
    "    input_dim = data_module.train_dataset.features.shape[1]\n",
    "    model = NN(\n",
    "        input_dim=input_dim,\n",
    "        hidden_dims=[512, 512, 256],\n",
    "        dropouts=[0.1, 0.1],\n",
    "        lr=1e-3,\n",
    "        weight_decay=5e-4\n",
    "    )\n",
    "    early_stopping = EarlyStopping('val_loss', patience=25, mode='min', verbose=False)\n",
    "    checkpoint_callback = ModelCheckpoint(monitor='val_loss', mode='min', save_top_k=1, verbose=False, \n",
    "                                          filename=\"/kaggle/working/single_model/model\") \n",
    "    timer = Timer()\n",
    "    trainer = Trainer(\n",
    "        max_epochs=2000,\n",
    "        accelerator=device,\n",
    "        logger=None,\n",
    "        callbacks=[early_stopping, checkpoint_callback, timer],\n",
    "        enable_progress_bar=False\n",
    "    )\n",
    "\n",
    "    trainer.fit(model, data_module.train_dataloader(4), data_module.val_dataloader(4))\n",
    "    print(f'Training completed in {timer.time_elapsed(\"train\"):.2f}s')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 9871156,
     "sourceId": 84493,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30840,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
